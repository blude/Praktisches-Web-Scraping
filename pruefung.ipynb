{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3688fd13",
   "metadata": {},
   "source": [
    "# Prüfung - Praktisches Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07633b04",
   "metadata": {},
   "source": [
    "## Vorstellung\n",
    "\n",
    "Sie sind ein Student des digitalen Designs und interessieren sich für Geschäftsstrategien. Daher bewahren Sie immer einen Ordner mit den aktuellsten Artikeln auf, den Sie offline lesen können, beispielsweise wenn Sie während Ihres Sommerurlaubs vom Stromnetz getrennt sind.\n",
    "\n",
    "Dazu müssen Sie die Kategorieseite „Strategie“ einer Ihrer Lieblingswebsites, **Fast Company**, durchsuchen.\n",
    "\n",
    "Nutzen Sie das Wissen, das Sie bisher über Pythons Listen-, Wörterbuch- und String-Methoden gesammelt haben, `for`-Schleifen, `if`-Anweisung, kombiniert mit `.select()` / `.select_one()`, `.find()` / `.find_all()`, `.parent`, `.text` und andere nützliche BeautifulSoup-Methoden zur Lösung der folgenden Herausforderung. \n",
    "\n",
    "Viel Spaß!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0b702",
   "metadata": {},
   "source": [
    "## Einstellung\n",
    "\n",
    "Verwenden Sie die URL unten, um die Nachrichtenartikel zu scrapen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ce3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fc_category = \"https://web.archive.org/web/20250822090500/https://www.fastcompany.com/section/strategy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9acc2",
   "metadata": {},
   "source": [
    "## Durchführung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d12385",
   "metadata": {},
   "source": [
    "Schließen Sie das Miniprojekt ab und übermitteln Sie Ihren Code und Ihre Ergebnisse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfd406",
   "metadata": {},
   "source": [
    "### Teil 1\n",
    "\n",
    "1. Scrapen Sie die Artikelkategorieseite mit der angegebenen URL.\n",
    "2. Suchen Sie den Abschnitt „Latest Strategy News“ und extrahieren Sie Titel, URL, Miniaturansicht, Beschreibungstext und Veröffentlichungsdatum des Artikels in ein Wörterbuch.\n",
    "3. Speichern Sie das Wörterbuch in einer Liste.\n",
    "\n",
    "Beispiel für das Format der Liste:\n",
    "\n",
    "```python\n",
    "list = [\n",
    "    {\n",
    "        \"url\": \"...\",\n",
    "        \"title\": \"...\",\n",
    "        \"description\": \"...\",\n",
    "        \"thumbnail\": {\n",
    "            \"url\": \"...\",\n",
    "            \"alt\": \"...\"\n",
    "        },\n",
    "        \"category\": {\n",
    "          \"url\": \"...\",\n",
    "          \"text\": \"...\"\n",
    "        }\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30370f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schreiben Sie hier Ihre Lösung für Teil 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfdbdb",
   "metadata": {},
   "source": [
    "### Teil 2\n",
    "\n",
    "Teil 2 setzt den vorherigen Teil fort.\n",
    "\n",
    "1. Holen Sie sich den ersten Nachrichtenartikel aus der Liste der neuesten Artikel, die Sie in Teil 1 gespeichert haben.\n",
    "2. Extrahieren Sie den Titel des Artikels und seinen Inhalt.\n",
    "2. Formatieren Sie die Daten und speichern Sie sie als gültige Markdown-Datei.\n",
    "\n",
    "**Wichtig**: Denken Sie daran, immer darauf zu achten, dass die URL, mit der Sie arbeiten, korrekt formatiert ist. Wenn sich die URL hinter einer Archivierungslösung wie der **Wayback Machine** befindet, möchten Sie möglicherweise zuerst die URL bereinigen und den folgenden Teil herausnehmen: `https://web.archive.org/web/20250822090500/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc010e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schreiben Sie hier Ihre Lösung für Teil 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e48ad",
   "metadata": {},
   "source": [
    "## Bewertungskriterien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806fbb9d",
   "metadata": {},
   "source": [
    "Ihre Leistung wird nach folgenden Kriterien bewertet:\n",
    "\n",
    "- **Aufgabenerledigung:** Alle Aufgaben werden wie beschrieben erledigt.\n",
    "- **Korrektheit:** Code läuft fehlerfrei und erzeugt die erwartete Ausgabe.\n",
    "\n",
    "### Bestehen des Kurses\n",
    "\n",
    "Der geschriebene Code muss nicht schön aussehen, sollte aber die erwarteten Ergebnisse und Ausgaben liefern. Der Lernende kann folgende Konzepte und Ansätze erfolgreich anwenden:\n",
    "\n",
    "- Holen Sie sich den Quellcode der Website; Headers bei Bedarf senden.\n",
    "- Betrachten Sie die Website visuell und den entsprechenden Quellcode, um die besten Orientierungspunkte und Elemente zu finden, die zum Scrapen der Informationen verwendet werden könnten\n",
    "- Verwenden Sie die entsprechenden Funktionen und Eigenschaften, die auf BeautifulSoup verfügbar sind, um die Daten zu extrahieren\n",
    "- Gehen Sie den DOM-Baum auf und ab\n",
    "- Verwenden Sie `for`-Schleife, `if`-Anweisungen, Listen, Worterbücher, JSON um korrektes Code zu erzeugen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59682fa2",
   "metadata": {},
   "source": [
    "## Lösungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede33eb7",
   "metadata": {},
   "source": [
    "### Teil 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501a5dd",
   "metadata": {},
   "source": [
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n",
    "  'Accept-Language': 'en-US,en;q=0.9',\n",
    "  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "}\n",
    "\n",
    "category_page = requests.get(url_fc_category)\n",
    "soup = BeautifulSoup(category_page.text, 'html.parser')\n",
    "\n",
    "latest_news_header = soup.find('h2')\n",
    "latest_articles = latest_news_header.parent.find('section').find_all('article')\n",
    "\n",
    "latest_articles_list = []\n",
    "\n",
    "for article in latest_articles:\n",
    "  article_category = article.contents[0]\n",
    "  article_info = article.contents[1]\n",
    "\n",
    "  article_details = {\n",
    "    'url': article_info.get('href', ''),\n",
    "    'title': article_info.find_all('p')[0].text,\n",
    "    'description': article_info.find_all('p')[1].text,\n",
    "    'thumbnail': {\n",
    "      \"url\": article_info.find('img').get('src', ''),\n",
    "      'alt': article_info.find('img').get('alt', '')\n",
    "    },\n",
    "    'category': {\n",
    "      'url': article_category.find('a').get('href', ''),\n",
    "      'text': article_info.find_all('p')[0].text\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  latest_articles_list.append(article_details)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0290a5f",
   "metadata": {},
   "source": [
    "### Teil 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e1f24",
   "metadata": {},
   "source": [
    "```python\n",
    "latest_article_url = latest_articles_list[0]['url']\n",
    "clean_url = 'https://' + latest_article_url.split('https://').pop()\n",
    "\n",
    "headers = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n",
    "  'Accept-Language': 'en-US,en;q=0.9',\n",
    "  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "}\n",
    "\n",
    "article_page = requests.get(clean_url, headers=headers)\n",
    "soup2 = BeautifulSoup(article_page.text, 'html.parser')\n",
    "\n",
    "article_title = soup2.h1.text.strip()\n",
    "article_elements = soup2.select_one('article').select('h2, p')\n",
    "\n",
    "article_content = []\n",
    "\n",
    "for element in article_elements:\n",
    "  if element.name == 'h2':\n",
    "    article_content.append(f'## {element.text.strip()}')\n",
    "  elif element.text.strip() == '|':\n",
    "    continue\n",
    "  else:\n",
    "    article_content.append(''.join([str(subelement) for subelement in element.contents]))\n",
    "\n",
    "article_content = '\\n\\n'.join(article_content)\n",
    "\n",
    "filename = clean_url.split('/').pop()\n",
    "with open(f'{filename}.md', 'w', encoding='utf-8') as file:\n",
    "  file.write(f'# {article_title}\\n')\n",
    "  file.write('\\n')\n",
    "  file.write(article_content)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
