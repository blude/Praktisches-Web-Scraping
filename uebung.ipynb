{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a92e34",
   "metadata": {},
   "source": [
    "# Übung - Praktisches Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9b427",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Anleitung\n",
    "\n",
    "Hallo! Dies ist ein interaktives Jupyter-Notebook. Nachfolgend finden Sie die Grundlagen zum Erlernen der Navigation und Verwendung dieses Tools.\n",
    "\n",
    "- **Ausführung von Zellen:**  \n",
    "    Klicken Sie auf eine Codezelle und drücken Sie `Shift + Enter` um es auszuführen. Die Ausgabe wird unterhalb der Zelle angezeigt.\n",
    "\n",
    "- **Hinzufügen von Zellen:**  \n",
    "    Verwenden Sie die Schaltfläche `+` in der Symbolleiste oder drücke `B` (unten) or `A` (oben) im Befehlsmodus, um neue Zellen hinzuzufügen.\n",
    "\n",
    "- **Bearbeiten von Zellen:**  \n",
    "    Doppelklicken Sie auf eine Zelle, um ihren Inhalt zu bearbeiten. Drücke `Esc` um den Bearbeitungsmodus zu verlassen.\n",
    "\n",
    "- **Speichern der Arbeit:**  \n",
    "    Klicken Sie auf das Speichersymbol oder drücken Sie `Ctrl + S` um Ihr Notebook zu speichern.\n",
    "\n",
    "- **Markdown-Zellen:**  \n",
    "    Verwenden Sie Markdown-Zellen für formatierten Text, Überschriften und Anweisungen. Ändern Sie eine Zelle in Markdown, indem Sie sie auswählen und `M` im Befehlsmodus drücken.\n",
    "\n",
    "- **Neustart des Kernels:**  \n",
    "    Wenn Ihr Code nicht mehr funktioniert, starten Sie den Kernel über das Menü neu (`Kernel > Restart`) und führen Sie die Zellen erneut aus.\n",
    "\n",
    "- **Geltungsbereich von Variablen:**  \n",
    "    In einer Zelle definierte Variablen und Importe können in anderen Zellen verwendet werden, solange der Kernel nicht neu gestartet wurde.\n",
    "\n",
    "- **Reihenfolge der Ausführung:**  \n",
    "    Die Reihenfolge, in der Sie Zellen betreiben, ist wichtig. Stellen Sie sicher, dass Sie Zellen ausführen, die Variablen definieren, oder Bibliotheken importieren, bevor Sie sie in anderen Zellen verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9cebe",
   "metadata": {},
   "source": [
    "## Einstellung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ba59d",
   "metadata": {},
   "source": [
    "### URLs\n",
    "\n",
    "Für die Durchführung der Übungen müssen Sie die folgenden URLs verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49a05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dw_article1 = \"https://web.archive.org/web/20250820004953/https://www.dw.com/de/treibt-frost-in-der-türkei-den-nutellapreis/a-73614362\"\n",
    "url_dw_category = \"https://web.archive.org/web/20250818134329/https://www.dw.com/de/wissenschaft/s-12296\"\n",
    "url_dw_video1 = \"https://web.archive.org/web/20250820192931/https://www.dw.com/de/ki-rezepte-und-roboterköche-die-zukunft-des-kochens/video-70794914\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f7863",
   "metadata": {},
   "source": [
    "## Durchführung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999c4ec",
   "metadata": {},
   "source": [
    "### Fragen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557a38f",
   "metadata": {},
   "source": [
    "#### Willkommensfrage\n",
    "\n",
    "Welche der folgenden Werte ist **NICHT** bekannt in einem `headers`-Definiton? \n",
    "\n",
    "- A) `'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0 Safari/537.36'`\n",
    "- B) `'Accept-Language': 'de-DE,de;q=0.9'`\n",
    "- C) `'X-Allow-All-Requests-From': 'crawlers, scrapers, robots'`\n",
    "- D) `'Accept-Encoding': 'gzip, deflate, br'`\n",
    "- E) `'Connection': 'keep-alive'`\n",
    "\n",
    "Bei Bedarf können Sie ebenfalls die richtigen verwenden, um Ihre eigene `headers`-Definition zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwort:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611b317",
   "metadata": {},
   "source": [
    "#### Frage 1\n",
    "Was bedeutet der Statuscode `200`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19740682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwort:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfde359",
   "metadata": {},
   "source": [
    "#### Frage 2\n",
    "What is the difference between `.find()` and `.select()` in BeautifulSoup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwort:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330b689",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "What's the difference between the `.find()`/`.find_all()` and `.select_one()`/`.select()` methods in BeautifulSoup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fd0ea",
   "metadata": {},
   "source": [
    "#### Frage 4\n",
    "Wie können Sie den Text innerhalb eines bestimmten HTML-Tags extrahieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwort:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750517ee",
   "metadata": {},
   "source": [
    "#### Frage 5\n",
    "\n",
    "Wie können Sie nun die URL aus einem Link extrahieren (`<a>` tag)?\n",
    "\n",
    "Es gibt mehrere Möglichkeiten, dies zu erreichen, aber versuchen Sie, mit der Methode zu antworten, die keinen Laufzeitfehler verursacht, wenn die URL nicht existiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc34924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwort:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76c977",
   "metadata": {},
   "source": [
    "#### Frage 6\n",
    "\n",
    "Welche der folgenden Optionen stellt den richtigen CSS-Selektor zum Abgleichen des **einen oder anderen** Elements dar?\n",
    "\n",
    "- A) `element + element`\n",
    "- B) `element, element`\n",
    "- C) `element > element`\n",
    "- D) `element ~ element`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef610c6b",
   "metadata": {},
   "source": [
    "#### Frage 7\n",
    "Which of the following correctly explains the key difference between JSON and CSV file formats?\n",
    "\n",
    "- A) JSON can represent hierarchical data structures, while CSV is limited to flat rows and columns.\n",
    "- B) CSV supports multiple data types (e.g., booleans, null) while JSON stores only text.\n",
    "- C) JSON files can only be read by programming languages, while CSV can be opened in any browser.\n",
    "- D) CSV is always faster and smaller than JSON, regardless of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d015839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwort:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851968c0",
   "metadata": {},
   "source": [
    "#### Frage 8\n",
    "Welche der folgenden Aussagen beschreibt eine Situation richtig, in der das Scraping von Daten von einer Website ethisch vertretbar ist? (Mehrere Optionen sind möglich)\n",
    "\n",
    "- A) Wenn die Website das Scraping in ihrer `robots.txt`-Datei ausdrücklich verbietet.\n",
    "- B) Wenn die Daten öffentlich verfügbar sind und nicht hinter einem Login oder einer Paywall.\n",
    "- C) Wenn Scraping die Server der Website nicht stark belastet.\n",
    "- D) Wenn Sie die Quelle der von Ihnen verwendeten Daten angeben.\n",
    "- E) Wenn beim Scraping personenbezogene oder sensible Daten ohne Einwilligung erhoben werden.\n",
    "- F) Wenn Sie die Nutzungsbedingungen der Website überprüfen, um zu bestätigen, dass die Nutzung zulässig ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec69ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwort:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c7b17",
   "metadata": {},
   "source": [
    "### Übungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ad5f3",
   "metadata": {},
   "source": [
    "Die folgenden Übungen wurden vorbereitet, damit Sie schrittweise den Umgang mit den Bibliotheken, Methoden und Funktionen erlernen können. Bei einigen Aufgaben müssen Sie die Lücken ausfüllen, bei anderen müssen Sie die Anleitung nachfolgen oder Ihre eigene Lösung finden.\n",
    "\n",
    "Viel Spaß beim Scraping!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec912b2",
   "metadata": {},
   "source": [
    "#### Willkommensübung\n",
    "\n",
    "Füllen sie die Lücken: Importieren Sie die `requests` und die `bs4` Module und zeigen Sie ihre Version mit dem `print()`-Methode und die `.__version__`-Eigenschaft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "______ requests, bs4\n",
    "\n",
    "______('requests:', _______)\n",
    "______('bs4:', ___________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fefff",
   "metadata": {},
   "source": [
    "Erwartete Ausgabe:\n",
    "\n",
    "```\n",
    "requests: 2.32.4\n",
    "bs4: 4.13.4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf940d3",
   "metadata": {},
   "source": [
    "#### Übung 1\n",
    "Rufen Sie die Artikel-Webseite mithilfe der URL `url_dw_article1` ab und drucken Sie den Statuscode und die Inhaltslänge aus.\n",
    "\n",
    "Tipp: Sie werden hier den Unterschied zwischen `response.text` und `response.content` verstehen müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60fe26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ~~Importiere das `requests`-Modul~~~ (geschafft!)\n",
    "# 2. Header so einstellen, dass sie einen Browser nachahmen (falls erforderlich)\n",
    "# 3. Machen Sie eine GET-Anfrage an die URL\n",
    "# 4. Statuscode und Inhaltslänge mit Hilfe von `.status_code`, `len()` anzeigen\n",
    "\n",
    "headers = {\n",
    "    \"_________\": \"_________\",\n",
    "    \"_________\": \"_________\",\n",
    "    \"_________\": \"_________\"\n",
    "}\n",
    "\n",
    "response = requests._____(__________, ___________=headers)\n",
    "\n",
    "_______('Status code:', response._________)\n",
    "_______('Length:', ____(response._________), 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f11c2",
   "metadata": {},
   "source": [
    "Erwartete Ausgabe:\n",
    "\n",
    "- `Status code: 200`\n",
    "- `Length: 150188 bytes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af406de",
   "metadata": {},
   "source": [
    "#### Übung 2\n",
    "Extrahieren und drucken Sie den Titel der Nachrichtenartikelseite.\n",
    "\n",
    "Tipp: Verwenden Sie die `.title` und `.text`-Eigenschaften von BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importieren Sie die `BeautifulSoup`-Klasse aus dem `bs4`-Modul\n",
    "# 2. Analysieren Sie den HTML-Inhalt der Seite und speichern Sie ihn in einer Variablen namens `soup`\n",
    "# 3. Extrahieren Sie den Titel der Seite und zeigen Sie ihn an\n",
    "\n",
    "from ____ import _________\n",
    "_____ = _________(response._________, 'html.parser')\n",
    "\n",
    "______(soup._________._________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce9dec",
   "metadata": {},
   "source": [
    "Erwartete Ausgabe:\n",
    "\n",
    "`Treibt Frost in der Türkei den Nutellapreis? – DW – 12.08.2025`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a796ea8",
   "metadata": {},
   "source": [
    "#### Übung 3\n",
    "\n",
    "Zeigen Sie den Quellcode des `<header>` Elements in einem lesbaren hübschen (_\"pretty\"_) Format an, indem Sie die Methode `.prettify()` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27986bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "______(soup.________.___________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7363d74e",
   "metadata": {},
   "source": [
    "Erwaterte Ausgabe:\n",
    "\n",
    "```\n",
    "<header class=\"sgeegmk\">\n",
    " <div class=\"kicker s1wafcin s1tby7rj lxmvniw icns9en rcjjkz7 w128axg5 b1fzgn0z\" data-tracking-name=\"content-detail-kicker\">\n",
    "  <span>\n",
    "   Handel\n",
    "  </span>\n",
    "  <span>\n",
    "   <a class=\"sngcpkw btl76l3 e1eo633p w128axg5 b1fzgn0z\" href=\"/de/europa/s-12322\" tabindex=\"0\">\n",
    "    Europa\n",
    "   </a>\n",
    "  </span>\n",
    " </div>\n",
    " <h1 class=\"daqvxdf h1du6kc5 l1ozsu87 p1s74fjj s16w0xvi sngcpkw b1fzgn0z\">\n",
    "  Treibt Frost in der Türkei den Nutellapreis?\n",
    " </h1>\n",
    " <div class=\"a9wq4ao author-details\">\n",
    "  <span>\n",
    "   <span class=\"no-link m1ho1h07 l1evdo4u blt0baw s16w0xvi sngcpkw w128axg5 b1fzgn0z\">\n",
    "    Nik Martin\n",
    "   </span>\n",
    "  </span>\n",
    " </div>\n",
    " <span class=\"time-area s1i8qhb9 lxmvniw icns9en rcjjkz7 w128axg5 b1fzgn0z\">\n",
    "  <span class=\"publication lxmvniw icns9en rcjjkz7 w128axg5 b1fzgn0z\">\n",
    "   <time aria-hidden=\"true\">\n",
    "    12.08.2025\n",
    "   </time>\n",
    "   <span class=\"sr-only s28j2rd\">\n",
    "    12. August 2025\n",
    "   </span>\n",
    "  </span>\n",
    " </span>\n",
    " <p class=\"teaser-text l1evdo4u blt0baw s16w0xvi sngcpkw w128axg5 b1fzgn0z\">\n",
    "  Frost im Frühjahr hat die türkische Haselnussernte hart getroffen. Europas Süßwarenhersteller leiden bereits unter hohen Kakaopreisen, nun könnten auch Produkte teurer werden, die Nüsse enthalten.\n",
    " </p>\n",
    "</header>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01864bd",
   "metadata": {},
   "source": [
    "#### Übung 4\n",
    "Finden Sie alle Überschriften der zweiten Ebene (`<h2>`-Tag) auf der Seite mit drei verschiedenen Ansätzen.\n",
    "\n",
    "Tipp: Verwenden Sie den Gleichheitsoperator `==` um zu überprüfen, ob das Ergebnis aller Ansätze identisch ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach1 = soup._________('____')\n",
    "approach2 = soup._________('____')\n",
    "approach3 = soup('____')\n",
    "_____(approach1 ____ approach2 ___ approach3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f2423",
   "metadata": {},
   "source": [
    "Ewarterte Ausgabe: `True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e09458",
   "metadata": {},
   "source": [
    "#### Übung 5\n",
    "Extrahieren Sie alle Links (`<a>`-Tag) mit den `.internal-link`-Klassname von der Webseite und zeigen Sie deren Text und URLs an.\n",
    "\n",
    "Hinweis: Man kann in Python die `class`-Attribut nicht verwenden, weil es geschützt ist. Verwenden Sie stattdessen das `class_`-Attribut.\n",
    "\n",
    "Tipp: Sie können eine `for`-Schleife verwenden, um über die Elemente zu iterieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5995571",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup._______('a', ______='___________'):\n",
    "    print(link._______, link.______('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a780ea",
   "metadata": {},
   "source": [
    "Erwaterte Ausgabe:\n",
    "\n",
    "```\n",
    "in der Türkei /de/türkei/t-17600264\n",
    "von einem verheerenden Frost /de/dossier-klimawandel/a-73389631\n",
    "Chile /de/chile/t-17909752\n",
    "USA /de/vereinigte-staaten-von-amerika-usa/t-17286012\n",
    "Georgien /de/georgien/t-18456307\n",
    "die Angst vor Engpässen /de/klima-iwf-flucht-migration-extremwetter-klimawandel-wohlstand-gesundheit-hitze-dürre/a-40742370\n",
    "Klimawandels /de/klimawandel/t-17477721\n",
    "die Klimakrise /de/klimawandel-europa-kämpft-mit-dürre-und-wassermangel-hitze-wassermanagement-wasser-v2/a-72351705\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f492107",
   "metadata": {},
   "source": [
    "#### Übung 6\n",
    "\n",
    "Suchen Sie dieses Mal mithilfe des in die folgende Lösung eingebetteten HTML den `.teaser`-Container, extrahieren und zeigen Sie den Titel, die URL, den Beschreibungstext, die Kategorie und das Veröffentlichungsdatum des Artikels sowie die URL der hochwertigen Version des Miniaturbilds und seinen Alternativtext an.\n",
    "\n",
    "Verwenden Sie die `.find()` und `select_one()` Methoden um die Elemente abzugleichen, `.get()` um Attribute zu extrahieren und `.text` zum Text.\n",
    "\n",
    "Verwenden Sie darüber hinaus die `.strip()`-Methode um zusätzliche Zeilen oder Leerzeichen aus den Zeichenketten zu entfernen.\n",
    "\n",
    "Tipp: die `code_snippet`-Variable kann direkt an die Funktion BeautifulSoup übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f966f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_snippet = \"\"\"\n",
    "<div data-tracking-list-item=\"true\" data-tracking-name=\"Teaser\" class=\"teaser-wrap\">\n",
    "  <div data-stats-id=\"73300850\" class=\"s1b19e59 teaser\">\n",
    "    <div class=\"teaser-image-wrap txn63vu\">\n",
    "      <a href=\"/de/südafrika-wenn-ki-im-gerichtssaal-fehler-macht/a-73300850\" title=\"Südafrika: Wenn KI im Gerichtssaal Fehler macht\" tabindex=\"-1\" class=\"teaser-image b1fzgn0z\">\n",
    "        <figure style=\"--responsive-picture-aspect-ratio-xs:1;--responsive-picture-aspect-ratio-sm:1.7777777777777777;--responsive-picture-aspect-ratio-md:1.7777777777777777;--responsive-picture-aspect-ratio-lg:1.7777777777777777;--responsive-picture-aspect-ratio-xl:1.7777777777777777;--responsive-picture-aspect-ratio-wide_xl:1.7777777777777777;\" class=\"srnoiv7 s1a75hd4 lazy-load-container\">\n",
    "          <img src aria-hidden=\"true\" alt=\"Die App von ChatGPT auf einem Smartphone\" class=\"lq-img\"/>\n",
    "          <img src alt=\"Die App von ChatGPT auf einem Smartphone\" title=\"Die App von ChatGPT auf einem Smartphone\" class=\"hq-img\"/>\n",
    "        </figure>\n",
    "      </a>\n",
    "      <div class=\"teaser-data-xs-sm\">\n",
    "        <h3 aria-hidden=\"false\" class=\"title-xs-sm title l1hyxzb2\">\n",
    "          <a href=\"/de/südafrika-wenn-ki-im-gerichtssaal-fehler-macht/a-73300850\" tabindex=\"0\" class=\"r72hb1q sngcpkw btl76l3 e1eo633p w128axg5 b1fzgn0z\">Südafrika: Wenn KI im Gerichtssaal Fehler macht</a>\n",
    "        </h3>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div class=\"teaser-data-wrap tp11brh\">\n",
    "      <div class=\"teaser-data\">\n",
    "        <h3 aria-hidden=\"false\" class=\"title-above-md title l1hyxzb2\">\n",
    "          <a href=\"/de/südafrika-wenn-ki-im-gerichtssaal-fehler-macht/a-73300850\" tabindex=\"0\" class=\"r72hb1q sngcpkw btl76l3 e1eo633p w128axg5 b1fzgn0z\">Südafrika: Wenn KI im Gerichtssaal Fehler macht</a>\n",
    "        </h3>\n",
    "        <div class=\"teaser-description l1360f57 l1evdo4u blt0baw s16w0xvi rcjjkz7 w128axg5 b1fzgn0z\">\n",
    "          <a href=\"/de/südafrika-wenn-ki-im-gerichtssaal-fehler-macht/a-73300850\" tabindex=\"-1\" class=\"lxnr2vj b1fzgn0z\">Nach dem fehlerhaften Gebrauch von künstlicher Intelligenz vor Gericht sorgen sich Juristen um ethische Standards.</a>\n",
    "        </div>\n",
    "      </div>\n",
    "      <div class=\"s16l2fqg teaser-footer-wrapper s1teu0c4\">\n",
    "        <span class=\"kicker lxmvniw icns9en rcjjkz7 w128axg5 b1fzgn0z\">Südafrika</span>\n",
    "        <span class=\"date-time lxmvniw icns9en rcjjkz7 w128axg5 b1fzgn0z\">\n",
    "          <time aria-hidden=\"true\">24.07.2025</time>\n",
    "          <span class=\"sr-only s28j2rd\">24. Juli 2025</span>\n",
    "        </span>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "______ = BeautifulSoup(__________, 'html.parser')\n",
    "\n",
    "teaser = ______._________('______', class_='_______')\n",
    "teaser_data = teaser.select_one('_________________')\n",
    "\n",
    "url = teaser_data.select_one('___').get('_______')\n",
    "title = teaser_data.select_one('_______').text.strip()\n",
    "description = teaser_data.select_one('_______').text.strip()\n",
    "category = teaser_data.select_one('_______').text.strip()\n",
    "published_date = teaser_data.select_one('_______').text.strip()\n",
    "\n",
    "thumbnail = teaser.select_one('_______ _______')\n",
    "thumbnail_src = thumbnail.get('_______')\n",
    "thumbnail_alt = thumbnail.get('_______')\n",
    "\n",
    "print('Article URL:', url)\n",
    "print('Title:', title)\n",
    "print('Description:', description)\n",
    "print('Published date:', published_date)\n",
    "print('Category:', category)\n",
    "\n",
    "print('Thumbnail URL:', thumbnail_src)\n",
    "print('Alt text:', thumbnail_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba19f80",
   "metadata": {},
   "source": [
    "Erwarterte Ausgabe:\n",
    "\n",
    "```\n",
    "Article URL: /de/südafrika-wenn-ki-im-gerichtssaal-fehler-macht/a-73300850\n",
    "Title: Südafrika: Wenn KI im Gerichtssaal Fehler macht\n",
    "Description: Nach dem fehlerhaften Gebrauch von künstlicher Intelligenz vor Gericht sorgen sich Juristen um ethische Standards.\n",
    "Published date: 24.07.2025\n",
    "Category: Südafrika\n",
    "Thumbnail URL: \n",
    "Alt text: Die App von ChatGPT auf einem Smartphone\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b48ef3",
   "metadata": {},
   "source": [
    "#### Übung 7\n",
    "\n",
    "Extrahieren Sie alle Artikelüberschriften von der Nachrichtenkategorieseite (`url_dw_category`) und zeigen Sie nur den Titel jedes Artikels an.\n",
    "\n",
    "Besuchen Sie im Zweifelsfall die oben genannte URL und überprüfen Sie mit der Funktion „Element-Informationen“ visuell, wie die Struktur der Seite tatsächlich aussieht.\n",
    "\n",
    "Wichtig:\n",
    "1. Achten Sie darauf, Elemente auszuschließen, die keine tatsächlichen Schlagzeilen sind (z.B. Sie enthalten keine `<a>`-Elemente).\n",
    "2. Auch doppelte Einträge sollten herausgefiltert werden.\n",
    "\n",
    "Tipp: Verwenden Sie Listen, `for`-Schleifen, `if`-Anweisung, `.contents` und `set()`. Es wäre auch keine schlechte Idee, die angeforderte Kategorieseite und die BeautifulSoup in neuen Variablen zu speichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2acf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_______ = requests.get(url_dw_category)\n",
    "_______ = BeautifulSoup(________, '_________')\n",
    "\n",
    "items = _____.select('____, _____')\n",
    "headlines = []\n",
    "\n",
    "for item in ______:\n",
    "    if item.________[0].name == '____':\n",
    "        headlines.______(item.________[0])\n",
    "\n",
    "unique_headlines = ______(headlines)\n",
    "\n",
    "for unique in _______________:\n",
    "    print(unique._______)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6fccc",
   "metadata": {},
   "source": [
    "Erwarterte Ausgabe:\n",
    "```\n",
    "Mexikos Lieferfahrerinnen kämpfen für mehr Sicherheit\n",
    "So schön wie auf Social Media? Die Hafenstadt Hamburg\n",
    "Mit taktilen Westen Musik fühlen können\n",
    "KI-Modell soll menschliches Verhalten vorhersagen \n",
    "Pflege per App: Risiko für Patienten?\n",
    "Schnellere Erde: Das steckt hinter dem \"kürzesten Tag\"\n",
    "Medizinischer KI-Chatbot - speziell für arabische Frauen\n",
    "50 Jahre europäische Raumfahrt: Happy Birthday, ESA!\n",
    "Warum gepökeltes Fleisch nicht auf den Grill gehört\n",
    "Wie Ecuador mit künstlicher Intelligenz Kolibris rettet\n",
    "Weltraum: Neue deutsche Raumkapsel startet für die Forschung\n",
    "Elternsein in Europa: weniger Zufriedenheit, mehr Lebenssinn\n",
    "Gefälschte Medikamente: Ein weltweites Problem\n",
    "Plastikmüll: Gelingt ein internationales Abkommen?\n",
    "Wer gewinnt den Wettlauf im Weltall?\n",
    "KI kann Sudokus lösen, aber nicht erklären\n",
    "Türkei: War prähistorisches Çatalhöyük ein Matriarchat?\n",
    "Vibrio-Bakterien in Europa: Sicher baden trotz Risiko\n",
    "Wie entwickelt sich die sexuelle Orientierung?\n",
    "Günstigere Prothesen dank 3D-Druck\n",
    "Liger, Maultier und Co.: Skurrile Mischlinge der Tierwelt\n",
    "Oft erst spät erkannt: Altersdepressionen\n",
    "Weltstillwoche: Muttermilch kann vor Brustkrebs schützen\n",
    "Boom bei deutschen Rüstungsstartups\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e800f9",
   "metadata": {},
   "source": [
    "#### Übung 8\n",
    "\n",
    "Fortsetzung der vorherigen Übung...\n",
    "\n",
    "Speichern Sie den Titel und die URL der extrahierten Überschriften in einer CSV-Datei mit dem Namen `headlines.csv`.\n",
    "\n",
    "Sie können eine Datei im Schreibmodus öffnen, indem Sie zunächst den folgenden Code verwenden:\n",
    "\n",
    "```python\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "```\n",
    "\n",
    "Tipp: Verwenden Sie die Methoden `.append()` von Listen und `.writer()`, `.write_row()` und `.write_rows()` vom `csv`-Modul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1fb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importieren Sie die CSV-Bibliothek\n",
    "# 2. Erstellen Sie eine Liste mit dem Titel und der URL jeder Überschrift\n",
    "# 3. Öffnen Sie eine CSV-Datei im Schreibmodus mit dem Namen `headlines.csv`\n",
    "# 4. Schreiben Sie die Kopfzeile mit 'Title' und 'URL'\n",
    "# 5. Schreiben Sie die Zeilen in die CSV-Datei\n",
    "\n",
    "import ____\n",
    "\n",
    "csv_rows = []\n",
    "\n",
    "for unique in ___________:\n",
    "    title = unique._____\n",
    "    url = unique.___('_____')\n",
    "    csv_rows.append([_____, _____])\n",
    "\n",
    "with open('_________', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(________)\n",
    "    writer.writerow(['_____', '_____'])\n",
    "    writer.writerows(_______)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a54b66",
   "metadata": {},
   "source": [
    "Erwartet Ausgabe:\n",
    "\n",
    "Datei `headlines.csv` wurde im Dateisystem gespeichert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316053c",
   "metadata": {},
   "source": [
    "#### Übung 9\n",
    "\n",
    "Einige Artikel auf der DW-Website enthalten ein vorgestelltes Video. Können Sie überprüfen, ob der abgekratzte Nachrichtenartikel (`url_dw_article1`) einen hat, und seine URL anzeigen?\n",
    "\n",
    "Wenn ein Video gefunden wurde, es oder keines seiner untergeordneten Elemente jedoch über das Attribut `src` verfügt, sollte das Attribut `poster` des Videoelements zurückgegeben werden.\n",
    "\n",
    "Andernfalls sollte, wenn kein Video gefunden wurde, die Meldung „No video found“ angezeigt werden.\n",
    "\n",
    "Ihr Code sollte niemals Laufzeitfehler verursachen. Einige Methoden von BeautilfulSoup, wie `.select_one()`, gibt `None` zurück, wenn nichts gefunden wird, während `.select()` gibt eine leere Liste zurück.\n",
    "\n",
    "Denken Sie daran: Das Video muss das vorgestellte sein, kein verwandtes Video.\n",
    "\n",
    "Tipp: Die Video-URL (`url_dw_video1`) kann als Beispiel für eine Seite verwendet werden, die ein Video enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f24d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Finden Sie das vorgestellte Video-Tag mit dem entsprechenden CSS-Selektor\n",
    "# 2. Extrahieren Sie die Video-URL aus dem Element `<source>` innerhalb des Elements\n",
    "# 3. Zeigen Sie die Video-URL oder eine Nachricht an, wenn keine gefunden wurde\n",
    "\n",
    "video_tags = soup.select('_______ video')\n",
    "\n",
    "if ________:\n",
    "    video_url = video_tags[__]._________('source').get('____')\n",
    "    if video_url == '':\n",
    "        video_url = video_tags[__].____('______')\n",
    "    ______(________)\n",
    "else:\n",
    "    print(\"___________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ae323",
   "metadata": {},
   "source": [
    "Erwartete Ausgabe: `No video found`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315920f",
   "metadata": {},
   "source": [
    "#### Übung 10\n",
    "\n",
    "Holen Sie sich alle Bilder, die Sie im Nachrichtenartikel finden und Speichern Sie sie in einem Wörterbuch namens `found_iamges`, das die Attribute `src`, `srcset`, `alt`, `width`, `height` and `class` jedes Bildes enthält.\n",
    "\n",
    "Drucken Sie das Wörterbuch auf die Konsole.\n",
    "\n",
    "Schließlich, nach dem Drucken des Wörterbuchs, eine JSON-Datei mit dem Namen `found_images.json` mit diesen Daten sollten gespeichert werden.\n",
    "\n",
    "Die Struktur des Wörterbuchs und der JSON-Datei sollte wie folgt aussehen:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"images\": [\n",
    "        {\n",
    "            \"id\": null,\n",
    "            \"attrs\": {\n",
    "                \"src\": \"https://example.com/image.jpg\",\n",
    "                \"srcset\": [\"https://example.com/image-600.jpg 600w\",\n",
    "                            \"https://example.com/image-1200.jpg 1200w\"],\n",
    "                \"alt\": \"An example image\",\n",
    "                \"width\": \"600\",\n",
    "                \"height\": \"400\",\n",
    "                \"class\": [\"example-class\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importieren Sie die JSON-Bibliothek\n",
    "# 2. Finden Sie alle Bild-Tags im `soup`-Objekt\n",
    "# 3. Erstellen Sie ein Wörterbuch, um die gefundenen Bilder zu speichern\n",
    "# 4. Iterieren Sie über die Bild-Tags und extrahieren Sie relevante Attribute\n",
    "# 5. Fügen Sie die Bild-ID und ihre Attribute der Liste der gefundenen Bilder hinzu\n",
    "# 6. Zeigen Sie das Wörterbuch mit den gefundenen Bilder an\n",
    "# 7. Speichern Sie das Wörterbuch in einer JSON-Datei mit dem Namen `found_images.json`\n",
    "\n",
    "import ____\n",
    "\n",
    "img_tags = soup.______('_____')\n",
    "\n",
    "found_images = {\n",
    "    'images': []\n",
    "}\n",
    "\n",
    "for img in ________:\n",
    "    img_attrs = {}\n",
    "    for attr in img.______.items():\n",
    "        if attr[__] in ['src', 'alt', 'width', 'height', 'class']:\n",
    "            # Behandeln Sie nur die ausgewählten Attribute\n",
    "            img_attrs[attr[__]] = attr[__]\n",
    "        elif attr[__] == 'srcset':\n",
    "            # Behandeln Sie srcset separat, um responsive Bild-URLs als Liste zu erhalten\n",
    "            srcset = [url.strip() for url in attr[1].______(',')]\n",
    "            img_attrs[attr[__]] = srcset\n",
    "    found_images['_______'].________({'id': img._____('id', ____), 'attrs': ______})\n",
    "\n",
    "print(___________)\n",
    "\n",
    "with open('__________', 'w', encoding='utf-8') as file:\n",
    "    ____.dump(_________, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f16bee7",
   "metadata": {},
   "source": [
    "Die Datei `found_images.json` wurde im Dateisystem gespeichert.\n",
    "\n",
    "Erwarterte Ausgabe:\n",
    "\n",
    "`'{'images': [{'id': None, 'attrs': {'src': '', 'srcset': ['https://static.dw.com/image/73598139_600.jpg 78w', 'https://static.dw.com/image/73598139_601.jpg 201w', 'https://static.dw.com/image/73598139_602.jpg 379w', 'https://static.dw.com/image/73598139_603.jpg 545w', 'https://static.dw.com/image/73598139_604.jpg 767w', 'https://static.dw.com/image/73598139_605.jpg 1199w'], 'width': '100', 'height': '56.25', 'alt': 'Nutella-Gläser im Supermarktregal'}}, {'id': None, 'attrs': {'alt': 'Landwirte bei der Haselnussernte im Hizan-Distrikt in der türkischen Provinz Bitlis'}}, {'id': None, 'attrs': {'alt': 'Auf einem Frühstücksbrettchen angerichtet: Weizenmischbrot mit Nuss-Nougat-Creme'}}, {'id': None, 'attrs': {'alt': 'Großes Angebot: Haselnüsse im Supermarkt im rheinischen Altenkirchen'}}, {'id': None, 'attrs': {'src': '', 'alt': 'Ein übergewichtiger Mann sitzt auf einer Bank und isst', 'class': ['lq-img']}}, {'id': None, 'attrs': {'src': '', 'alt': 'Ein übergewichtiger Mann sitzt auf einer Bank und isst', 'class': ['hq-img']}}, {'id': None, 'attrs': {'src': '', 'alt': 'Eine Person hält einen deutschen Reisepass in der Hand, im Hintergrund der Flughafen-Wartebereich ', 'class': ['lq-img']}}, {'id': None, 'attrs': {'src': '', 'alt': 'Eine Person hält einen deutschen Reisepass in der Hand, im Hintergrund der Flughafen-Wartebereich ', 'class': ['hq-img']}}]}'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4546ff",
   "metadata": {},
   "source": [
    "## Lösungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0580b",
   "metadata": {},
   "source": [
    "### Fragen\n",
    "\n",
    "#### Willkommensfrage\n",
    "\n",
    "Die Option C) `\"X-Allow-All-Requests-From\": „Crawler, Scraper, Roboter\"` ist keine bekannte oder gültige Header-Eigenschaft.\n",
    "\n",
    "#### Frage 1\n",
    "\n",
    "Der HTTP-Statuscode `200` zeigt an, dass eine Anfrage erfolgreich war und die angeforderten Daten korrekt vom Server an den Browser übertragen wurden.\n",
    "\n",
    "#### Frage 2\n",
    "\n",
    "Die Methode `.find()` ermöglicht das Abgleichen von Elementen mithilfe von Tag-Namen + Attributen, während die Methode `.select()` CSS-Selektoren verwendet.\n",
    "\n",
    "#### Frage 3\n",
    "\n",
    "`.select()` und `.find_all()` stimmen mit allen Elementen überein, während `.select_one()` und `.find()` nur mit dem ersten gefundenen Element übereinstimmen.\n",
    "\n",
    "#### Frage 4\n",
    "\n",
    "Durch Verwendung entweder der Methode `.get_text()` oder der Eigenschaften `.text`, `.string` oder `.string_stripped` auf einem Element.\n",
    "\n",
    "#### Frage 5\n",
    "\n",
    "Die Methode `.get('href')` kann verwendet werden, um die URL eines Links abzurufen.\n",
    "\n",
    "#### Frage 6\n",
    "\n",
    "Option B) `element, element` ist der richtige CSS-Selektor, der dem einen oder anderen Element entspricht.\n",
    "\n",
    "#### Frage 7\n",
    "\n",
    "Option A) ist richtig.\n",
    "\n",
    "#### Frage 8\n",
    "\n",
    "Die Optionen B), C), D) und F) sind richtig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cabb07",
   "metadata": {},
   "source": [
    "### Übungen\n",
    "\n",
    "#### Willkommensübung\n",
    "\n",
    "```python\n",
    "import requests, bs4\n",
    "\n",
    "print('requests:', requests.__version__)\n",
    "print('bs4:', bs4.__version__)\n",
    "```\n",
    "\n",
    "#### Übung 1\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(url_dw_article1)\n",
    "print(\"Status code: \", response.status_code)\n",
    "print(\"Length:\", len(response.content), 'bytes')\n",
    "```\n",
    "\n",
    "#### Übung 2\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup.title.text)\n",
    "```\n",
    "\n",
    "#### Übung 3\n",
    "\n",
    "```python\n",
    "print(soup.header.prettify())\n",
    "```\n",
    "\n",
    "#### Übung 4\n",
    "\n",
    "```python\n",
    "approach1 = soup.find_all('h2')\n",
    "approach2 = soup.select('h2')\n",
    "approach3 = soup('h2')\n",
    "print(approach1 == approach2 == approach3)\n",
    "```\n",
    "\n",
    "#### Übung 5\n",
    "\n",
    "```python\n",
    "for link in soup.find_all('a', class_='internal-link'):\n",
    "    print(link.text, link.get('href'))\n",
    "```\n",
    "\n",
    "#### Übung 6\n",
    "\n",
    "```python\n",
    "soup2 = BeautifulSoup(code_snippet, 'html.parser')\n",
    "\n",
    "teaser = soup2.find('div', class_='teaser')\n",
    "teaser_data = teaser.select_one('.teaser-data-wrap')\n",
    "\n",
    "url = teaser_data.select_one('a').get('href')\n",
    "title = teaser_data.select_one('h3.title').text.strip()\n",
    "description = teaser_data.select_one('.teaser-description').text.strip()\n",
    "category = teaser_data.select_one('.kicker').text.strip()\n",
    "published_date = teaser_data.select_one('time').text.strip()\n",
    "\n",
    "thumbnail = teaser.select_one('.teaser-image-wrap .hq-img')\n",
    "thumbnail_src = thumbnail.get('src')\n",
    "thumbnail_alt = thumbnail.get('alt')\n",
    "\n",
    "print('Article URL:', url)\n",
    "print('Title:', title)\n",
    "print('Description:', description)\n",
    "print('Published date:', published_date)\n",
    "print('Category:', category)\n",
    "\n",
    "print('Thumbnail URL:', thumbnail_src)\n",
    "print('Alt text:', thumbnail_alt)\n",
    "```\n",
    "\n",
    "#### Übung 7\n",
    "\n",
    "```python\n",
    "response = requests.get(url_dw_category)\n",
    "soup3 = BeautifulSoup(response3.text, 'html.parser')\n",
    "\n",
    "items = soup3.select('h3, h4')\n",
    "headlines = []\n",
    "\n",
    "for item in items:\n",
    "    if item.contents[0].name == 'a':\n",
    "        headlines.append(item.contents[0])\n",
    "\n",
    "unique_headlines = set(headlines)\n",
    "\n",
    "for unique in unique_headlines:\n",
    "    print(unique.text)\n",
    "```\n",
    "\n",
    "#### Übung 8\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "csv_rows = []\n",
    "\n",
    "for unique in unique_headlines:\n",
    "    title = unique.text\n",
    "    url = unique.get('href')\n",
    "    csv_rows.append([title, url])\n",
    "\n",
    "with open('headlines.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Title', 'URL'])\n",
    "    writer.writerows(csv_rows)\n",
    "```\n",
    "\n",
    "#### Übung 9\n",
    "\n",
    "```python\n",
    "video_tags = soup.select('.av-player video')\n",
    "\n",
    "if video_tags:\n",
    "    video_url = video_tags[0].select_one('source').get('src')\n",
    "    if video_url == '':\n",
    "      video_url = video_tags[0].get('poster')\n",
    "    print(video_url)\n",
    "else:\n",
    "    print(\"No video found\")\n",
    "```\n",
    "\n",
    "#### Übung 10\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "img_tags = soup.select('img')\n",
    "\n",
    "found_images = {\n",
    "    'images': []\n",
    "}\n",
    "\n",
    "for img in img_tags:\n",
    "    img_attrs = {}\n",
    "    for attr in img.attrs.items():\n",
    "        if attr[0] in ['src', 'alt', 'width', 'height', 'class']:\n",
    "            # Behandeln Sie nur die ausgewählten Attribute\n",
    "            img_attrs[attr[0]] = attr[1]\n",
    "        elif attr[0] == 'srcset':\n",
    "            # Behandeln Sie srcset separat, um responsive Bild-URLs als Liste zu erhalten\n",
    "            srcset = [url.strip() for url in attr[1].split(',')]\n",
    "            img_attrs[attr[0]] = srcset\n",
    "    found_images['images'].append({'id': img.get('id', None), 'attrs': img_attrs})\n",
    "\n",
    "print(found_images)\n",
    "\n",
    "with open(\"found_images.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(found_images, file, ensure_ascii=False, indent=4)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
